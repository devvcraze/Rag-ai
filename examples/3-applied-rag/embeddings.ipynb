{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d566bb99-6808-4976-8476-ed05b7941b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/_0hrdmkn5bdcs8mzhjtd7w7c0000gn/T/ipykernel_29348/3557198016.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../top_rated_wines.csv')\n",
    "df = df[df['variety'].notna()] # remove any NaN values as it blows up serialization\n",
    "data = df.sample(700).to_dict('records') # Get only 700 records. More records will make it slower to index\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8bce2c-e123-498a-a5f2-cefffd17fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0e4be5-7518-4458-bf47-6913ef9a72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer('all-MiniLM-L6-v2') # Model to create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5efa031d-b18a-4db1-9c34-9989a15c822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vector database client\n",
    "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03be93-a076-425e-8df1-5a8b6367e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection to store wines\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=\"top_wines\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d08af-758f-4338-b112-cf94045c7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize!\n",
    "qdrant.upload_points(\n",
    "    collection_name=\"top_wines\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            vector=encoder.encode(doc[\"notes\"]).tolist(),\n",
    "            payload=doc,\n",
    "        ) for idx, doc in enumerate(data) # data is the variable holding all the wines\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Suggest me an amazing Malbec wine from Argentina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9bff5-db38-4a98-b542-cd173af11b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search time for awesome wines!\n",
    "\n",
    "hits = qdrant.search(\n",
    "    collection_name=\"top_wines\",\n",
    "    query_vector=encoder.encode(user_prompt).tolist(),\n",
    "    limit=3\n",
    ")\n",
    "for hit in hits:\n",
    "  print(hit.payload, \"score:\", hit.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33243e5d-9e0d-4ec4-98e9-3fc56b8bdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable to hold the search results\n",
    "search_results = [hit.payload for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now time to connect to the local large language model\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8080/v1\", # \"http://<Your api-server IP>:port\"\n",
    "    api_key = \"sk-no-key-required\"\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"LLaMA_CPP\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are chatbot, a wine specialist. Your top priority is to help guide users into selecting amazing wine and guide them with their requests.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Suggest me an amazing Malbec wine from Argentina\"},\n",
    "        {\"role\": \"assistant\", \"content\": str(search_results)}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
